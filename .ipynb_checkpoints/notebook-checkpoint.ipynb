{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from konlpy.tag import Mecab;tagger=Mecab()\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://arxiv.org/pdf/1703.00955.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.0+751198f'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = open('../dataset/naver_test.txt','r',encoding='utf-8').readlines()\n",
    "data = data[1:]\n",
    "data = [[d.split('\\t')[1],d.split('\\t')[2][:-1]] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distibution = [d[1] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(distibution)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for t in data:\n",
    "    t0 = t[0]\n",
    "    t0 = t0.replace(\"<br>\",\"\")\n",
    "    t0 = t0.replace(\"/\",\"\")\n",
    "    \n",
    "    token0 = tagger.morphs(t0)\n",
    "    \n",
    "    if len(token0)>=SEQ_LENGTH:\n",
    "        token0= token0[:SEQ_LENGTH-1]\n",
    "    token0.append(\"<EOS>\")\n",
    "\n",
    "    while len(token0)<SEQ_LENGTH:\n",
    "        token0.append('<PAD>')\n",
    "    \n",
    "    train.append([token0,token0,t[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2index={\"<PAD>\":0,\"<SOS>\":1,\"<EOS>\":2,\"<UNK>\":3}\n",
    "\n",
    "for t in train:\n",
    "    for token in t[0]:\n",
    "        if token not in word2index:\n",
    "            word2index[token]=len(word2index)\n",
    "\n",
    "index2word = {v:k for k,v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = list(map(lambda w: to_ix[w] if w in to_ix.keys() else to_ix[\"<UNK>\"], seq))\n",
    "    tensor = Variable(torch.LongTensor(idxs)).cuda() if USE_CUDA else Variable(torch.LongTensor(idxs))\n",
    "    return tensor\n",
    "\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x=[]\n",
    "train_y=[]\n",
    "code_labels=[]\n",
    "lengths=[]\n",
    "for tr in train:\n",
    "    temp = prepare_sequence(tr[0], word2index)\n",
    "    temp = temp.view(1,-1)\n",
    "    train_x.append(temp)\n",
    "\n",
    "    temp2 = prepare_sequence(tr[1],word2index)\n",
    "    temp2 = temp2.view(1,-1)\n",
    "    train_y.append(temp2)\n",
    "    \n",
    "    length = [t for t in tr[1] if t !='<PAD>']\n",
    "    lengths.append(len(length))\n",
    "    code_labels.append(Variable(torch.LongTensor([int(tr[2])])).cuda() if USE_CUDA else Variable(torch.LongTensor([int(tr[2])])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = list(zip(train_x,train_y,code_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBatch(batch_size,train_data):\n",
    "    random.shuffle(train_data)\n",
    "    sindex=0\n",
    "    eindex=batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex:eindex]\n",
    "        x,y,c = zip(*batch)\n",
    "        x,y,c = torch.cat(x),torch.cat(y),torch.cat(c)\n",
    "        temp = eindex\n",
    "        eindex = eindex+batch_size\n",
    "        sindex = temp\n",
    "        \n",
    "        yield (x,y,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,latent_size=10,n_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.Wmu= nn.Linear(hidden_size,latent_size)\n",
    "        self.Wsigma = nn.Linear(hidden_size,latent_size)\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,batch_first=True)\n",
    "    \n",
    "    def reparametrize(self, mu, log_var):\n",
    "        \"\"\"\"z = mean + eps * sigma where eps is sampled from N(0, 1).\"\"\"\n",
    "        eps = Variable(torch.randn(mu.size(0), mu.size(1))).cuda() if USE_CUDA else Variable(torch.randn(mu.size(0), mu.size(1)))\n",
    "        z = mu + eps * torch.exp(log_var/2)    # 2 for convert var to std\n",
    "        return z\n",
    "    \n",
    "    def forward(self, input,train=True):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, input.size(0), self.hidden_size)).cuda() if USE_CUDA else Variable(torch.zeros(self.n_layers, input.size(0), self.hidden_size))\n",
    "        \n",
    "        embedded = self.embedding(input)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        mu = self.Wmu(hidden[-1])\n",
    "        log_var = self.Wsigma(hidden[-1])\n",
    "        z = self.reparametrize(mu, log_var)\n",
    "        \n",
    "        return z,mu,log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size,latent_size=10,code_size=2, n_layers=1):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        #self.Wz = nn.Linear(latent_size+code_size,hidden_size)\n",
    "        self.Wz = nn.Linear(latent_size,hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "\n",
    "        #self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, self.n_layers,batch_first=True)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input,latent,code,lengths,seq_length,training=True):\n",
    "        \n",
    "\n",
    "        embedded = self.embedding(input)\n",
    "        #embedded = self.dropout(embedded)\n",
    "       \n",
    "        # h0\n",
    "        #latent_code = torch.cat((latent,code),1) # z,c\n",
    "        #hidden = self.tanh(self.Wz(latent_code)).view(self.n_layers,input.size(0),-1) \n",
    "        hidden = self.tanh(self.Wz(latent)).view(self.n_layers,input.size(0),-1) \n",
    "        decode=[]\n",
    "        # Apply GRU to the output so far\n",
    "        for i in range(seq_length):\n",
    "            \n",
    "            _, hidden = self.gru(embedded, hidden)\n",
    "            score = self.out(hidden.view(hidden.size(0)*hidden.size(1),-1))\n",
    "            softmaxed = F.log_softmax(score)\n",
    "            decode.append(softmaxed)\n",
    "            _,input = torch.max(softmaxed,1)\n",
    "            embedded = self.embedding(input.unsqueeze(1))\n",
    "            #embedded = self.dropout(embedded)\n",
    "        \n",
    "        # 요고 주의! time-step을 column-wise concat한 후, reshape!!\n",
    "        scores = torch.cat(decode,1)\n",
    "        \n",
    "        return scores.view(input.size(0)*seq_length,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class  Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_num,embed_dim,class_num,kernel_num,kernel_sizes,dropout):\n",
    "        super(Discriminator,self).__init__()\n",
    "        #self.args = args\n",
    "        \n",
    "        V = embed_num # num of vocab\n",
    "        D = embed_dim # dimenstion of word vector\n",
    "        C = class_num # num of class\n",
    "        Ci = 1\n",
    "        Co = kernel_num # 100\n",
    "        Ks = kernel_sizes # [3,4,5]\n",
    "\n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        #self.convs1 = [nn.Conv2d(Ci, Co, (K, D)) for K in Ks]\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        \n",
    "        # kernal_size = (K,D) : D는 단어 벡터 길이라 픽스, K 사이즈만큼 슬라이딩, 스트라이드는 1\n",
    "        \n",
    "        '''\n",
    "        self.conv13 = nn.Conv2d(Ci, Co, (3, D))\n",
    "        self.conv14 = nn.Conv2d(Ci, Co, (4, D))\n",
    "        self.conv15 = nn.Conv2d(Ci, Co, (5, D))\n",
    "        '''\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3) #(N,Co,W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def forward(self, x,train=True):\n",
    "        x = self.embed(x) # (N,W,D)\n",
    "        \n",
    "        #if self.args.static:\n",
    "        #    x = Variable(x)\n",
    "\n",
    "        x = x.unsqueeze(1) # (N,Ci,W,D)\n",
    "\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1] #[(N,Co,W), ...]*len(Ks)\n",
    "\n",
    "\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x] #[(N,Co), ...]*len(Ks)\n",
    "\n",
    "        x = torch.cat(x, 1)\n",
    "\n",
    "        '''\n",
    "        x1 = self.conv_and_pool(x,self.conv13) #(N,Co)\n",
    "        x2 = self.conv_and_pool(x,self.conv14) #(N,Co)\n",
    "        x3 = self.conv_and_pool(x,self.conv15) #(N,Co)\n",
    "        x = torch.cat((x1, x2, x3), 1) # (N,len(Ks)*Co)\n",
    "        '''\n",
    "        if train:\n",
    "            x = self.dropout(x) # (N,len(Ks)*Co)\n",
    "        logit = self.fc1(x) # (N,C)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 300\n",
    "LATENT_SIZE = 20\n",
    "CODE_SIZE = 2\n",
    "BATCH_SIZE=32\n",
    "STEP=5\n",
    "LEARNING_RATE=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder =  Encoder(len(word2index), HIDDEN_SIZE,LATENT_SIZE, 2)\n",
    "generator = Generator(HIDDEN_SIZE,len(word2index),LATENT_SIZE,CODE_SIZE)\n",
    "discriminator = Discriminator(len(word2index),100,2,30,[3,4,5],0.8)\n",
    "if USE_CUDA:\n",
    "    encoder = encoder.cuda()\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "    \n",
    "Recon = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "\n",
    "enc_optim= torch.optim.Adam(encoder.parameters(), lr=LEARNING_RATE)\n",
    "gen_optim = torch.optim.Adam(generator.parameters(),lr=LEARNING_RATE)\n",
    "dis_optiom = torch.optim.Adam(discriminator.parameters(),lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize base VAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/5] [0/1500] ELBO : 3.3468 , RECON : 3.3468 & KLD : 6670.8203\n",
      "[0/5] [100/1500] ELBO : 3.4580 , RECON : 3.4580 & KLD : 7041.8418\n",
      "[0/5] [200/1500] ELBO : 3.5261 , RECON : 3.5261 & KLD : 6760.3994\n",
      "[0/5] [300/1500] ELBO : 3.4681 , RECON : 3.4681 & KLD : 7006.5933\n",
      "[0/5] [400/1500] ELBO : 3.0258 , RECON : 3.0258 & KLD : 6842.7642\n",
      "[0/5] [500/1500] ELBO : 3.5526 , RECON : 3.5526 & KLD : 7191.9653\n",
      "[0/5] [600/1500] ELBO : 3.3330 , RECON : 3.3330 & KLD : 7257.8271\n",
      "[0/5] [700/1500] ELBO : 3.4401 , RECON : 3.4401 & KLD : 7233.2148\n",
      "[0/5] [800/1500] ELBO : 3.7362 , RECON : 3.7362 & KLD : 7167.5479\n",
      "[0/5] [900/1500] ELBO : 3.3602 , RECON : 3.3602 & KLD : 7119.2549\n",
      "[0/5] [1000/1500] ELBO : 3.5877 , RECON : 3.5877 & KLD : 7134.8066\n",
      "[0/5] [1100/1500] ELBO : 3.6376 , RECON : 3.6376 & KLD : 7197.6606\n",
      "[0/5] [1200/1500] ELBO : 3.8847 , RECON : 3.8847 & KLD : 7473.9912\n",
      "[0/5] [1300/1500] ELBO : 3.3178 , RECON : 3.3178 & KLD : 7365.9517\n",
      "[0/5] [1400/1500] ELBO : 3.6806 , RECON : 3.6806 & KLD : 7302.0786\n",
      "[0/5] [1500/1500] ELBO : 3.7918 , RECON : 3.7918 & KLD : 7369.0864\n",
      "[1/5] [0/1500] ELBO : 2.9745 , RECON : 2.9745 & KLD : 7455.5493\n",
      "[1/5] [100/1500] ELBO : 3.3640 , RECON : 3.3640 & KLD : 7360.2905\n",
      "[1/5] [200/1500] ELBO : 3.5379 , RECON : 3.5379 & KLD : 7592.8320\n",
      "[1/5] [300/1500] ELBO : 3.2883 , RECON : 3.2883 & KLD : 7561.4160\n",
      "[1/5] [400/1500] ELBO : 3.6518 , RECON : 3.6518 & KLD : 7642.5415\n",
      "[1/5] [500/1500] ELBO : 3.3352 , RECON : 3.3352 & KLD : 7591.1392\n",
      "[1/5] [600/1500] ELBO : 3.3389 , RECON : 3.3389 & KLD : 7646.9375\n",
      "[1/5] [700/1500] ELBO : 3.4699 , RECON : 3.4699 & KLD : 7802.8721\n",
      "[1/5] [800/1500] ELBO : 3.5726 , RECON : 3.5726 & KLD : 7697.4414\n",
      "[1/5] [900/1500] ELBO : 3.5089 , RECON : 3.5089 & KLD : 7688.3555\n",
      "[1/5] [1000/1500] ELBO : 3.5456 , RECON : 3.5456 & KLD : 7669.5303\n",
      "[1/5] [1100/1500] ELBO : 3.3925 , RECON : 3.3925 & KLD : 7797.0859\n",
      "[1/5] [1200/1500] ELBO : 3.6750 , RECON : 3.6750 & KLD : 7829.2231\n",
      "[1/5] [1300/1500] ELBO : 3.3489 , RECON : 3.3489 & KLD : 7732.4233\n",
      "[1/5] [1400/1500] ELBO : 3.4764 , RECON : 3.4764 & KLD : 7837.8379\n",
      "[1/5] [1500/1500] ELBO : 3.5859 , RECON : 3.5859 & KLD : 7977.1221\n",
      "[2/5] [0/1500] ELBO : 3.1965 , RECON : 3.1965 & KLD : 8149.6328\n",
      "[2/5] [100/1500] ELBO : 2.9487 , RECON : 2.9487 & KLD : 8092.7866\n",
      "[2/5] [200/1500] ELBO : 3.0322 , RECON : 3.0322 & KLD : 8036.2183\n",
      "[2/5] [300/1500] ELBO : 3.1034 , RECON : 3.1034 & KLD : 8142.3223\n",
      "[2/5] [400/1500] ELBO : 3.2646 , RECON : 3.2646 & KLD : 8250.5820\n",
      "[2/5] [500/1500] ELBO : 3.1316 , RECON : 3.1316 & KLD : 8003.9634\n",
      "[2/5] [600/1500] ELBO : 3.2836 , RECON : 3.2836 & KLD : 8306.3662\n",
      "[2/5] [700/1500] ELBO : 3.3844 , RECON : 3.3844 & KLD : 8172.9580\n",
      "[2/5] [800/1500] ELBO : 3.0418 , RECON : 3.0418 & KLD : 8397.0801\n",
      "[2/5] [900/1500] ELBO : 3.3053 , RECON : 3.3053 & KLD : 8445.2568\n",
      "[2/5] [1000/1500] ELBO : 3.0751 , RECON : 3.0751 & KLD : 7992.3076\n",
      "[2/5] [1100/1500] ELBO : 3.2423 , RECON : 3.2423 & KLD : 8248.4854\n",
      "[2/5] [1200/1500] ELBO : 3.3466 , RECON : 3.3466 & KLD : 8131.1416\n",
      "[2/5] [1300/1500] ELBO : 3.0587 , RECON : 3.0587 & KLD : 8321.0049\n",
      "[2/5] [1400/1500] ELBO : 3.4547 , RECON : 3.4547 & KLD : 8280.8926\n",
      "[2/5] [1500/1500] ELBO : 3.4247 , RECON : 3.4247 & KLD : 8549.1270\n",
      "[3/5] [0/1500] ELBO : 3.3589 , RECON : 3.3589 & KLD : 8462.5566\n",
      "[3/5] [100/1500] ELBO : 3.0707 , RECON : 3.0707 & KLD : 8319.1777\n",
      "[3/5] [200/1500] ELBO : 3.2707 , RECON : 3.2707 & KLD : 8707.8838\n",
      "[3/5] [300/1500] ELBO : 3.1329 , RECON : 3.1329 & KLD : 8557.0381\n",
      "[3/5] [400/1500] ELBO : 3.5001 , RECON : 3.5001 & KLD : 8907.0205\n",
      "[3/5] [500/1500] ELBO : 3.3150 , RECON : 3.3150 & KLD : 8563.1152\n",
      "[3/5] [600/1500] ELBO : 3.3392 , RECON : 3.3392 & KLD : 8606.7148\n",
      "[3/5] [700/1500] ELBO : 3.2573 , RECON : 3.2573 & KLD : 8681.0938\n",
      "[3/5] [800/1500] ELBO : 3.1230 , RECON : 3.1230 & KLD : 8640.8682\n",
      "[3/5] [900/1500] ELBO : 3.2443 , RECON : 3.2443 & KLD : 8565.6113\n",
      "[3/5] [1000/1500] ELBO : 3.0735 , RECON : 3.0735 & KLD : 8572.5625\n",
      "[3/5] [1100/1500] ELBO : 3.0362 , RECON : 3.0362 & KLD : 8278.9424\n",
      "[3/5] [1200/1500] ELBO : 3.2813 , RECON : 3.2813 & KLD : 8599.5410\n",
      "[3/5] [1300/1500] ELBO : 3.3268 , RECON : 3.3268 & KLD : 8632.9395\n",
      "[3/5] [1400/1500] ELBO : 3.0845 , RECON : 3.0845 & KLD : 8617.1367\n",
      "[3/5] [1500/1500] ELBO : 3.3340 , RECON : 3.3340 & KLD : 8607.4922\n",
      "[4/5] [0/1500] ELBO : 3.0370 , RECON : 3.0370 & KLD : 8603.6797\n",
      "[4/5] [100/1500] ELBO : 2.8753 , RECON : 2.8753 & KLD : 8712.2842\n",
      "[4/5] [200/1500] ELBO : 2.9017 , RECON : 2.9017 & KLD : 8809.6514\n",
      "[4/5] [300/1500] ELBO : 3.2713 , RECON : 3.2713 & KLD : 8829.5430\n",
      "[4/5] [400/1500] ELBO : 3.0387 , RECON : 3.0387 & KLD : 9044.0703\n",
      "[4/5] [500/1500] ELBO : 3.2017 , RECON : 3.2017 & KLD : 9220.5020\n",
      "[4/5] [600/1500] ELBO : 3.4299 , RECON : 3.4299 & KLD : 8793.7861\n",
      "[4/5] [700/1500] ELBO : 2.9780 , RECON : 2.9780 & KLD : 8717.3896\n",
      "[4/5] [800/1500] ELBO : 3.1076 , RECON : 3.1076 & KLD : 8740.5303\n",
      "[4/5] [900/1500] ELBO : 3.3457 , RECON : 3.3457 & KLD : 8900.0098\n",
      "[4/5] [1000/1500] ELBO : 3.4295 , RECON : 3.4295 & KLD : 9127.2002\n",
      "[4/5] [1100/1500] ELBO : 3.4343 , RECON : 3.4343 & KLD : 9065.9883\n",
      "[4/5] [1200/1500] ELBO : 3.0455 , RECON : 3.0455 & KLD : 9158.8838\n",
      "[4/5] [1300/1500] ELBO : 3.1624 , RECON : 3.1624 & KLD : 9192.9365\n",
      "[4/5] [1400/1500] ELBO : 3.3599 , RECON : 3.3599 & KLD : 9075.4424\n",
      "[4/5] [1500/1500] ELBO : 3.0640 , RECON : 3.0640 & KLD : 9299.6982\n"
     ]
    }
   ],
   "source": [
    "for step in range(STEP):\n",
    "    for i,(x,y,c) in enumerate(getBatch(BATCH_SIZE,train_data)):\n",
    "        #KCA = 0.3\n",
    "        encoder.zero_grad()\n",
    "        generator.zero_grad()\n",
    "\n",
    "        generator_input = Variable(torch.LongTensor([[word2index['<SOS>']]*BATCH_SIZE])).transpose(1,0)\n",
    "\n",
    "        if USE_CUDA:\n",
    "            generator_input = generator_input.cuda()\n",
    "\n",
    "        latent, mu, log_var = encoder(x)\n",
    "        \n",
    "        # 이 때, 코드는 prior p(c)에서 샘플링한다 되있는데, 이게 맞나.. 일단 유니폼 가정\n",
    "        code = Variable(torch.randn([BATCH_SIZE,2]).uniform_(0,1)).cuda() if USE_CUDA else Variable(torch.randn([BATCH_SIZE,2]).uniform_(0,1))\n",
    "\n",
    "        score = generator(generator_input,latent,code,lengths,SEQ_LENGTH)\n",
    "        recon_loss=Recon(score,y.view(-1))\n",
    "        kld_loss = torch.sum(0.5 * (mu**2 + torch.exp(log_var) - log_var -1))\n",
    "\n",
    "    #     KL_COST_ANNEALING\n",
    "        cost_annealing_check = recon_loss.data.cpu().numpy()[0] if USE_CUDA else recon_loss.data.numpy()[0]\n",
    "        if cost_annealing_check<1.5:\n",
    "            KCA = 1.0 # KL cost term annealing\n",
    "\n",
    "        else:\n",
    "            KCA = 0.0\n",
    "        ELBO = recon_loss+KCA*kld_loss\n",
    "\n",
    "        ELBO.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm(encoder.parameters(), 5.0)\n",
    "        torch.nn.utils.clip_grad_norm(generator.parameters(), 5.0)\n",
    "\n",
    "        gen_optim.step()\n",
    "        enc_optim.step()\n",
    "\n",
    "        if i % 100==0:\n",
    "            elbo_for_print = ELBO.data.cpu().numpy()[0] if USE_CUDA else ELBO.data.numpy()[0]\n",
    "            recon_for_print = recon_loss.data.cpu().numpy()[0] if USE_CUDA else recon_loss.data.numpy()[0]\n",
    "            kld_for_print = kld_loss.data.cpu().numpy()[0] if USE_CUDA else kld_loss.data.numpy()[0]\n",
    "            print(\"[%d/%d] [%d/%d] ELBO : %.4f , RECON : %.4f & KLD : %.4f\" % (step,STEP,i,1500,elbo_for_print,\n",
    "                                                                                  recon_for_print,\n",
    "                                                                                  kld_for_print))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 우선 VRAE 초기화가 잘 되는지 체크(kl cost annealing 제대로)\n",
    "* Encoder 진짜 length만\n",
    "* 다른 로스들도 실험\n",
    "* wakeup-sleep 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
